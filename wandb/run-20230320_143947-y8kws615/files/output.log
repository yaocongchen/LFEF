
  0%|                                                                                                                                                                                  | 0/150 [00:00<?, ?it/s]
----- Training - Epoch 01 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[1/150] train_iter: (10/64) 	 loss: 1.134891 acc:0.207390
=====> epoch[1/150] train_iter: (20/64) 	 loss: 0.879685 acc:0.407589
=====> epoch[1/150] train_iter: (30/64) 	 loss: 0.807934 acc:0.449949
=====> epoch[1/150] train_iter: (40/64) 	 loss: 0.955661 acc:0.368274
=====> epoch[1/150] train_iter: (50/64) 	 loss: 1.052180 acc:0.460413
=====> epoch[1/150] train_iter: (60/64) 	 loss: 1.012641 acc:0.395937
----- Training - Epoch 02 - batch_size 2,------
=====> the number of iterations per epoch:  64

  1%|█▏                                                                                                                                                                        | 1/150 [00:04<11:34,  4.66s/it]
=====> epoch[2/150] train_iter: (20/64) 	 loss: 0.974058 acc:0.239919
=====> epoch[2/150] train_iter: (30/64) 	 loss: 0.857390 acc:0.418261
=====> epoch[2/150] train_iter: (40/64) 	 loss: 0.967690 acc:0.472952
=====> epoch[2/150] train_iter: (50/64) 	 loss: 1.012744 acc:0.522443
=====> epoch[2/150] train_iter: (60/64) 	 loss: 0.853227 acc:0.539599
----- Training - Epoch 03 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[3/150] train_iter: (10/64) 	 loss: 1.125352 acc:0.339232

  1%|██▎                                                                                                                                                                       | 2/150 [00:08<10:09,  4.12s/it]
=====> epoch[3/150] train_iter: (30/64) 	 loss: 0.871466 acc:0.283591
=====> epoch[3/150] train_iter: (40/64) 	 loss: 0.799646 acc:0.411684
=====> epoch[3/150] train_iter: (50/64) 	 loss: 0.806203 acc:0.554831

  2%|███▍                                                                                                                                                                      | 3/150 [00:12<09:40,  3.95s/it]
----- Training - Epoch 04 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[4/150] train_iter: (10/64) 	 loss: 0.758458 acc:0.396294
=====> epoch[4/150] train_iter: (20/64) 	 loss: 0.882929 acc:0.377256
=====> epoch[4/150] train_iter: (30/64) 	 loss: 0.885957 acc:0.268474
=====> epoch[4/150] train_iter: (40/64) 	 loss: 0.685974 acc:0.503134
=====> epoch[4/150] train_iter: (50/64) 	 loss: 1.090670 acc:0.136170
=====> epoch[4/150] train_iter: (60/64) 	 loss: 0.733856 acc:0.503138
----- Training - Epoch 05 - batch_size 2,------

  3%|████▌                                                                                                                                                                     | 4/150 [00:15<09:24,  3.86s/it]
=====> epoch[5/150] train_iter: (10/64) 	 loss: 0.791600 acc:0.444475
=====> epoch[5/150] train_iter: (20/64) 	 loss: 0.904851 acc:0.324910
=====> epoch[5/150] train_iter: (30/64) 	 loss: 0.734473 acc:0.560952

  3%|█████▋                                                                                                                                                                    | 5/150 [00:19<09:14,  3.82s/it]
=====> epoch[5/150] train_iter: (50/64) 	 loss: 0.764751 acc:0.467487
=====> epoch[5/150] train_iter: (60/64) 	 loss: 0.916136 acc:0.486996
----- Training - Epoch 06 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[6/150] train_iter: (10/64) 	 loss: 0.787199 acc:0.436607
=====> epoch[6/150] train_iter: (20/64) 	 loss: 0.941705 acc:0.306311
=====> epoch[6/150] train_iter: (30/64) 	 loss: 0.827872 acc:0.379101

  4%|██████▊                                                                                                                                                                   | 6/150 [00:23<09:06,  3.80s/it]
=====> epoch[6/150] train_iter: (50/64) 	 loss: 0.676867 acc:0.529847
=====> epoch[6/150] train_iter: (60/64) 	 loss: 0.778522 acc:0.591100
----- Training - Epoch 07 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[7/150] train_iter: (10/64) 	 loss: 0.947083 acc:0.232318
=====> epoch[7/150] train_iter: (20/64) 	 loss: 0.901325 acc:0.293832
=====> epoch[7/150] train_iter: (30/64) 	 loss: 0.930978 acc:0.463941
=====> epoch[7/150] train_iter: (40/64) 	 loss: 0.706935 acc:0.538983

  5%|███████▉                                                                                                                                                                  | 7/150 [00:27<09:00,  3.78s/it]
=====> epoch[7/150] train_iter: (60/64) 	 loss: 0.797582 acc:0.455543
----- Training - Epoch 08 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[8/150] train_iter: (10/64) 	 loss: 0.706297 acc:0.538974
=====> epoch[8/150] train_iter: (20/64) 	 loss: 0.802162 acc:0.394568
=====> epoch[8/150] train_iter: (30/64) 	 loss: 0.781426 acc:0.511689
=====> epoch[8/150] train_iter: (40/64) 	 loss: 0.790297 acc:0.374480

  5%|█████████                                                                                                                                                                 | 8/150 [00:30<08:55,  3.77s/it]
=====> epoch[8/150] train_iter: (60/64) 	 loss: 0.990190 acc:0.484841
----- Training - Epoch 09 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[9/150] train_iter: (10/64) 	 loss: 0.978451 acc:0.349384
=====> epoch[9/150] train_iter: (20/64) 	 loss: 0.754250 acc:0.380277
=====> epoch[9/150] train_iter: (30/64) 	 loss: 0.632948 acc:0.570020
=====> epoch[9/150] train_iter: (40/64) 	 loss: 0.813826 acc:0.400478
=====> epoch[9/150] train_iter: (50/64) 	 loss: 0.657887 acc:0.536487

  6%|██████████▏                                                                                                                                                               | 9/150 [00:34<08:50,  3.76s/it]
----- Training - Epoch 10 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[10/150] train_iter: (10/64) 	 loss: 0.729053 acc:0.408253
=====> epoch[10/150] train_iter: (20/64) 	 loss: 0.761909 acc:0.433493
=====> epoch[10/150] train_iter: (30/64) 	 loss: 0.842290 acc:0.471644
=====> epoch[10/150] train_iter: (40/64) 	 loss: 0.693503 acc:0.488832
=====> epoch[10/150] train_iter: (50/64) 	 loss: 0.728685 acc:0.531394

  7%|███████████▎                                                                                                                                                             | 10/150 [00:38<08:45,  3.75s/it]
----- Training - Epoch 11 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[11/150] train_iter: (10/64) 	 loss: 0.744559 acc:0.598034
=====> epoch[11/150] train_iter: (20/64) 	 loss: 0.982563 acc:0.234460
=====> epoch[11/150] train_iter: (30/64) 	 loss: 1.030048 acc:0.408280
=====> epoch[11/150] train_iter: (40/64) 	 loss: 0.959664 acc:0.312218
=====> epoch[11/150] train_iter: (50/64) 	 loss: 0.656569 acc:0.518013
=====> epoch[11/150] train_iter: (60/64) 	 loss: 0.692881 acc:0.527924
----- Training - Epoch 12 - batch_size 2,------

  7%|████████████▍                                                                                                                                                            | 11/150 [00:42<08:40,  3.75s/it]
=====> epoch[12/150] train_iter: (10/64) 	 loss: 0.721704 acc:0.450928
=====> epoch[12/150] train_iter: (20/64) 	 loss: 0.896919 acc:0.361317
=====> epoch[12/150] train_iter: (30/64) 	 loss: 0.695060 acc:0.433034
=====> epoch[12/150] train_iter: (40/64) 	 loss: 0.672361 acc:0.515217
=====> epoch[12/150] train_iter: (50/64) 	 loss: 0.654006 acc:0.583118

  8%|█████████████▌                                                                                                                                                           | 12/150 [00:45<08:36,  3.75s/it]
----- Training - Epoch 13 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[13/150] train_iter: (10/64) 	 loss: 0.740664 acc:0.386855
=====> epoch[13/150] train_iter: (20/64) 	 loss: 0.764015 acc:0.440854

  9%|██████████████▋                                                                                                                                                          | 13/150 [00:49<08:36,  3.77s/it]
=====> epoch[13/150] train_iter: (40/64) 	 loss: 0.652019 acc:0.490240
=====> epoch[13/150] train_iter: (50/64) 	 loss: 0.690181 acc:0.463995
=====> epoch[13/150] train_iter: (60/64) 	 loss: 0.655540 acc:0.540044
----- Training - Epoch 14 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[14/150] train_iter: (10/64) 	 loss: 0.683253 acc:0.483288
=====> epoch[14/150] train_iter: (20/64) 	 loss: 0.732741 acc:0.528436

  9%|███████████████▊                                                                                                                                                         | 14/150 [00:53<08:39,  3.82s/it]
=====> epoch[14/150] train_iter: (40/64) 	 loss: 0.790724 acc:0.368488
=====> epoch[14/150] train_iter: (50/64) 	 loss: 0.877868 acc:0.376006
=====> epoch[14/150] train_iter: (60/64) 	 loss: 0.699806 acc:0.510095
----- Training - Epoch 15 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[15/150] train_iter: (10/64) 	 loss: 0.735803 acc:0.464691
=====> epoch[15/150] train_iter: (20/64) 	 loss: 0.745261 acc:0.418128

 10%|████████████████▉                                                                                                                                                        | 15/150 [00:57<08:34,  3.81s/it]
=====> epoch[15/150] train_iter: (40/64) 	 loss: 0.662643 acc:0.568199
=====> epoch[15/150] train_iter: (50/64) 	 loss: 0.701762 acc:0.520371
=====> epoch[15/150] train_iter: (60/64) 	 loss: 0.661894 acc:0.485292
----- Training - Epoch 16 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[16/150] train_iter: (10/64) 	 loss: 0.747665 acc:0.503325
=====> epoch[16/150] train_iter: (20/64) 	 loss: 0.819538 acc:0.340287
=====> epoch[16/150] train_iter: (30/64) 	 loss: 0.828658 acc:0.389917

 11%|██████████████████                                                                                                                                                       | 16/150 [01:01<08:29,  3.81s/it]
=====> epoch[16/150] train_iter: (50/64) 	 loss: 0.579015 acc:0.591387
=====> epoch[16/150] train_iter: (60/64) 	 loss: 0.677133 acc:0.453144
----- Training - Epoch 17 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[17/150] train_iter: (10/64) 	 loss: 0.706762 acc:0.396090
=====> epoch[17/150] train_iter: (20/64) 	 loss: 0.687099 acc:0.385580
=====> epoch[17/150] train_iter: (30/64) 	 loss: 0.657618 acc:0.573616

 11%|███████████████████▏                                                                                                                                                     | 17/150 [01:04<08:26,  3.81s/it]
=====> epoch[17/150] train_iter: (50/64) 	 loss: 0.786886 acc:0.531645
=====> epoch[17/150] train_iter: (60/64) 	 loss: 0.641121 acc:0.515639
----- Training - Epoch 18 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[18/150] train_iter: (10/64) 	 loss: 0.803900 acc:0.340880
=====> epoch[18/150] train_iter: (20/64) 	 loss: 0.789570 acc:0.265190
=====> epoch[18/150] train_iter: (30/64) 	 loss: 0.588192 acc:0.570754

 12%|████████████████████▎                                                                                                                                                    | 18/150 [01:08<08:24,  3.82s/it]
=====> epoch[18/150] train_iter: (50/64) 	 loss: 0.707641 acc:0.418319
=====> epoch[18/150] train_iter: (60/64) 	 loss: 0.827117 acc:0.397481
----- Training - Epoch 19 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[19/150] train_iter: (10/64) 	 loss: 0.654019 acc:0.479365
=====> epoch[19/150] train_iter: (20/64) 	 loss: 0.940024 acc:0.159836
=====> epoch[19/150] train_iter: (30/64) 	 loss: 0.693832 acc:0.450388
=====> epoch[19/150] train_iter: (40/64) 	 loss: 0.616077 acc:0.504974

 13%|█████████████████████▍                                                                                                                                                   | 19/150 [01:12<08:23,  3.84s/it]
=====> epoch[19/150] train_iter: (60/64) 	 loss: 0.996219 acc:0.138586
----- Training - Epoch 20 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[20/150] train_iter: (10/64) 	 loss: 0.708174 acc:0.390849
=====> epoch[20/150] train_iter: (20/64) 	 loss: 0.773402 acc:0.383929
=====> epoch[20/150] train_iter: (30/64) 	 loss: 0.661833 acc:0.537863
=====> epoch[20/150] train_iter: (40/64) 	 loss: 0.693272 acc:0.440097
 13%|█████████████████████▍                                                                                                                                                   | 19/150 [01:12<08:23,  3.84s/it]/home/yaocong/Experimental/light_ssd/lightssd.py:12: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  c = int(x.size()[1])
 13%|█████████████████████▍                                                                                                                                                   | 19/150 [01:16<08:48,  4.03s/it]
Traceback (most recent call last):
  File "/home/yaocong/Experimental/light_ssd/train.py", line 263, in <module>
    train(args)
  File "/home/yaocong/Experimental/light_ssd/train.py", line 218, in train
    torch.onnx.export(model, onnx_img_image, model_file_nameonnx, verbose=False)
  File "/home/yaocong/miniconda3/envs/torch/lib/python3.9/site-packages/torch/onnx/utils.py", line 504, in export
    _export(
  File "/home/yaocong/miniconda3/envs/torch/lib/python3.9/site-packages/torch/onnx/utils.py", line 1529, in _export
    graph, params_dict, torch_out = _model_to_graph(
  File "/home/yaocong/miniconda3/envs/torch/lib/python3.9/site-packages/torch/onnx/utils.py", line 1115, in _model_to_graph
    graph = _optimize_graph(
  File "/home/yaocong/miniconda3/envs/torch/lib/python3.9/site-packages/torch/onnx/utils.py", line 663, in _optimize_graph
    graph = _C._jit_pass_onnx(graph, operator_export_type)
  File "/home/yaocong/miniconda3/envs/torch/lib/python3.9/site-packages/torch/onnx/utils.py", line 1889, in _run_symbolic_function
    raise errors.UnsupportedOperatorError(
torch.onnx.errors.UnsupportedOperatorError: Exporting the operator 'aten::_convolution_mode' to ONNX opset version 14 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues
=====> epoch[20/150] train_iter: (60/64) 	 loss: 0.599162 acc:0.563147