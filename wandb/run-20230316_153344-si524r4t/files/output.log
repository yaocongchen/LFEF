
  0%|                                                                                                                                                               | 0/150 [00:00<?, ?it/s]
----- Training - Epoch 01 - batch_size 2,------
=====> the number of iterations per epoch:  2276
=====> epoch[1/150] train_iter: (10/2276) 	 loss: 1.039265 acc:0.365924
=====> epoch[1/150] train_iter: (20/2276) 	 loss: 1.000670 acc:0.398411
=====> epoch[1/150] train_iter: (30/2276) 	 loss: 0.881779 acc:0.523113
=====> epoch[1/150] train_iter: (40/2276) 	 loss: 0.964843 acc:0.375242
=====> epoch[1/150] train_iter: (50/2276) 	 loss: 0.956356 acc:0.516440
=====> epoch[1/150] train_iter: (60/2276) 	 loss: 1.033918 acc:0.281710
=====> epoch[1/150] train_iter: (70/2276) 	 loss: 0.940634 acc:0.434435
=====> epoch[1/150] train_iter: (80/2276) 	 loss: 0.857757 acc:0.563801
=====> epoch[1/150] train_iter: (90/2276) 	 loss: 1.133840 acc:0.119421
=====> epoch[1/150] train_iter: (100/2276) 	 loss: 0.944613 acc:0.380478
  0%|                                                                                                                                                               | 0/150 [00:07<?, ?it/s]
Traceback (most recent call last):
  File "/home/yaocong/Experimental/light_ssd/train.py", line 270, in <module>
    train(args)
  File "/home/yaocong/Experimental/light_ssd/train.py", line 170, in train
    loss.backward()
  File "/home/yaocong/miniconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/yaocong/miniconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt