  0%|                                                                                                                                                                                  | 0/150 [00:00<?, ?it/s]
 20%|██████████████████████████████████▌                                                                                                                                       | 13/64 [00:01<00:03, 13.35it/s]
----- Training - Epoch 01 - batch_size 2,------
=====> the number of iterations per epoch:  64

 77%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                       | 49/64 [00:03<00:00, 17.73it/s]
=====> epoch[1/150] train_iter: (20/64) 	 loss: 1.094838 acc:0.454721
=====> epoch[1/150] train_iter: (30/64) 	 loss: 0.997697 acc:0.347134
  1%|█▏                                                                                                                                                                        | 1/150 [00:04<11:49,  4.76s/it]
 25%|██████████████████████████████████████████▌                                                                                                                               | 16/64 [00:00<00:02, 17.75it/s]
=====> epoch[1/150] train_iter: (50/64) 	 loss: 0.924183 acc:0.351307
=====> epoch[1/150] train_iter: (60/64) 	 loss: 0.995985 acc:0.280514
----- Training - Epoch 02 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[2/150] train_iter: (10/64) 	 loss: 0.832235 acc:0.427325
=====> epoch[2/150] train_iter: (20/64) 	 loss: 0.869511 acc:0.469900
=====> epoch[2/150] train_iter: (30/64) 	 loss: 0.900312 acc:0.354867
=====> epoch[2/150] train_iter: (40/64) 	 loss: 0.929876 acc:0.302408

 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 52/64 [00:02<00:00, 17.78it/s]
=====> epoch[2/150] train_iter: (60/64) 	 loss: 0.877076 acc:0.448526
----- Training - Epoch 03 - batch_size 2,------
=====> the number of iterations per epoch:  64
=====> epoch[3/150] train_iter: (10/64) 	 loss: 0.969576 acc:0.440645
  1%|██▎                                                                                                                                                                       | 2/150 [00:08<10:23,  4.21s/it]
 31%|█████████████████████████████████████████████████████▏                                                                                                                    | 20/64 [00:01<00:02, 17.79it/s]
=====> epoch[3/150] train_iter: (30/64) 	 loss: 0.884360 acc:0.336923
=====> epoch[3/150] train_iter: (40/64) 	 loss: 0.785664 acc:0.398309
  1%|██▎                                                                                                                                                                       | 2/150 [00:11<14:09,  5.74s/it]
Traceback (most recent call last):
  File "/home/yaocong/Experimental/light_ssd/train.py", line 263, in <module>
    train(args)
  File "/home/yaocong/Experimental/light_ssd/train.py", line 157, in train
    loss.backward()
  File "/home/yaocong/miniconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/yaocong/miniconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt